{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:14.651824Z",
     "start_time": "2020-12-09T12:18:14.638828Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:19.174456Z",
     "start_time": "2020-12-09T12:18:15.965630Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Concatenate, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Cropping2D, Softmax, Activation, Reshape, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:24.201968Z",
     "start_time": "2020-12-09T12:18:23.013791Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "[tf.config.experimental.set_memory_growth(gpu, True) for gpu in gpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:24.635069Z",
     "start_time": "2020-12-09T12:18:24.629068Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "target_size = (128,128,3)\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "batch_size = 16\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:25.100606Z",
     "start_time": "2020-12-09T12:18:25.085603Z"
    }
   },
   "outputs": [],
   "source": [
    "l2 = tf.keras.regularizers.l2(l=weight_decay)\n",
    "def msdu_net():\n",
    "    input_img = Input(shape=target_size, name='input')\n",
    "    \n",
    "    # extractor1/unet1\n",
    "    e1_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', dilation_rate=1, kernel_regularizer=l2, kernel_initializer='he_normal', name='extractor1')(input_img)\n",
    "    e1_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv1_1')(e1_out)\n",
    "    e1_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv1_2')(e1_out)\n",
    "    m1_out = MaxPooling2D((2,2), strides=2, name='unet1_3')(e1_out)\n",
    "    \n",
    "    # extractor2\n",
    "    e2_out = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', dilation_rate=2, kernel_regularizer=l2, kernel_initializer='he_normal', name='extractor2')(input_img)\n",
    "    e2_out = Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv2_1')(e2_out)\n",
    "    e2_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv2_2')(e2_out)\n",
    "    c2_out = Concatenate(name='concat12')([m1_out, e2_out])\n",
    "    \n",
    "    # unet2\n",
    "    u2_out = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet2_1')(c2_out)\n",
    "    u2_out = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet2_2')(u2_out)\n",
    "    m2_out = MaxPooling2D((2,2), strides=2, name='unet2_3')(u2_out)\n",
    "    \n",
    "    # extractor3\n",
    "    e3_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', dilation_rate=2, kernel_regularizer=l2, kernel_initializer='he_normal', name='extractor3')(input_img)\n",
    "    e3_out = Conv2D(filters=128, kernel_size=3, strides=4, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv3_1')(e3_out)\n",
    "    e3_out = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv3_2')(e3_out)\n",
    "    c3_out = Concatenate(name='concat23')([m2_out, e3_out])\n",
    "    \n",
    "    # unet3\n",
    "    u3_out = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet3_1')(c3_out)\n",
    "    u3_out = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet3_2')(u3_out)\n",
    "    m3_out = MaxPooling2D((2,2), strides=2, name='unet3_3')(u3_out)\n",
    "    \n",
    "    # extractor4\n",
    "    e4_out = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', dilation_rate=2, kernel_regularizer=l2, kernel_initializer='he_normal', name='extractor4')(input_img)\n",
    "    e4_out = Conv2D(filters=256, kernel_size=3, strides=8, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv4_1')(e4_out)\n",
    "    e4_out = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='conv4_2')(e4_out)\n",
    "    c4_out = Concatenate(name='concat34')([m3_out, e4_out])\n",
    "    \n",
    "    # unet4\n",
    "    u4_out = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet4_1')(c4_out)\n",
    "    u4_out = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet4_2')(u4_out)\n",
    "    m4_out = MaxPooling2D((2,2), strides=2, name='unet4_3')(u4_out)\n",
    "    \n",
    "    # unet5 (bottom)\n",
    "    u5_out = Conv2D(filters=1024, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet5_1')(m4_out)\n",
    "    u5_out = Conv2D(filters=1024, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet5_2')(u5_out)\n",
    "    u5_out = Conv2DTranspose(filters=512, kernel_size=2, strides=2, padding='same', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet5_3')(u5_out)\n",
    "    c5_out = Concatenate(name='concat_up45')([u4_out, u5_out])\n",
    "    \n",
    "#     # unet6\n",
    "    u6_out = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet6_1')(c5_out)\n",
    "    u6_out = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet6_2')(u6_out)\n",
    "    u6_out = Conv2DTranspose(filters=256, kernel_size=2, strides=2, padding='same', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet6_3')(u6_out)\n",
    "    c6_out = Concatenate(name='concat_up36')([u3_out, u6_out])\n",
    "    \n",
    "    # unet7\n",
    "    u7_out = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet7_1')(c6_out)\n",
    "    u7_out = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet7_2')(u7_out)\n",
    "    u7_out = Conv2DTranspose(filters=128, kernel_size=2, strides=2, padding='same', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet7_3')(u7_out)\n",
    "    c7_out = Concatenate(name='concat_up27')([u2_out, u7_out])\n",
    "    \n",
    "    # unet8\n",
    "    u8_out = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet8_1')(c7_out)\n",
    "    u8_out = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet8_2')(u8_out)\n",
    "    u8_out = Conv2DTranspose(filters=64, kernel_size=2, strides=2, padding='same', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet8_3')(u8_out)\n",
    "    c8_out = Concatenate(name='concat_up18')([e1_out, u8_out])\n",
    "    \n",
    "    # unet9\n",
    "    u9_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet9_1')(c8_out)\n",
    "    u9_out = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2, kernel_initializer='he_normal', name='unet9_2')(u9_out)\n",
    "    u9_out = Conv2D(filters=1, kernel_size=1, strides=1, padding='same', name='unet9_3')(u9_out)\n",
    "    u9_out = BatchNormalization(name='unet9_4')(u9_out)\n",
    "    u9_out = Activation('sigmoid', name='output')(u9_out)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=u9_out, name='MSDU-NET')\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:27.494303Z",
     "start_time": "2020-12-09T12:18:26.365593Z"
    }
   },
   "outputs": [],
   "source": [
    "model = msdu_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:28.168736Z",
     "start_time": "2020-12-09T12:18:27.495303Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='msdu-net.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:28.369965Z",
     "start_time": "2020-12-09T12:18:28.356962Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_and_contrast(img, mask):\n",
    "    if (np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask / 255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img, mask)\n",
    "\n",
    "def dataGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode=\"grayscale\",\n",
    "                    mask_color_mode=\"grayscale\", target_size=(256,256), seed=1, shuffle=False):\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        img, mask = normalize_and_contrast(img, mask)\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:33.909063Z",
     "start_time": "2020-12-09T12:18:33.662026Z"
    }
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "#                     brightness_range=[0.5,1.5],\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.1,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "train_dir = './dataset/Training'\n",
    "val_dir = './dataset/Test'\n",
    "\n",
    "\n",
    "train_size = len(list(Path(train_dir).glob('**/*.png')))\n",
    "val_size = len(list(Path(val_dir).glob('**/*.png')))\n",
    "print(train_size, val_size)\n",
    "\n",
    "\n",
    "train_data = dataGenerator(batch_size,\n",
    "                            train_dir,\n",
    "                            'image',\n",
    "                            'gt',\n",
    "                            data_gen_args,\n",
    "                            image_color_mode='rgb',\n",
    "                            target_size=target_size[:2],\n",
    "                            shuffle=True)\n",
    "\n",
    "val_data = dataGenerator(batch_size,\n",
    "                          val_dir,\n",
    "                          'image',\n",
    "                          'gt',\n",
    "                          dict(),\n",
    "                          image_color_mode='rgb',\n",
    "                          target_size=target_size[:2],\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:18:34.995294Z",
     "start_time": "2020-12-09T12:18:34.989799Z"
    }
   },
   "outputs": [],
   "source": [
    "def decay(epoch, lr):\n",
    "    return lr * 0.1 if (epoch % 25 == 0) and epoch != 0 else lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T12:54:11.457601Z",
     "start_time": "2020-12-09T12:18:37.269810Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('ckpt-msdu-net-tvt.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "\n",
    "lr_schedule = LearningRateScheduler(decay, verbose=1)\n",
    "\n",
    "history = model.fit_generator(train_data,\n",
    "                              steps_per_epoch=math.ceil(train_size/batch_size),\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_data,\n",
    "                              validation_steps=math.ceil(val_size/batch_size),\n",
    "                              callbacks=[model_checkpoint, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T13:11:53.584061Z",
     "start_time": "2020-12-09T13:11:53.197043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result Visualization\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "\n",
    "acc_train = history.history['binary_accuracy']\n",
    "acc_val = history.history['val_binary_accuracy']\n",
    "\n",
    "epochs_ax = history.epoch\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_ax, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs_ax, loss_val, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy Visualization\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_ax, acc_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs_ax, acc_val, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('History.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:31:32.434856Z",
     "start_time": "2020-12-09T09:31:31.945534Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_name = 'MSDU_Net.h5'\n",
    "\n",
    "if not os.path.exists(saved_name):\n",
    "    model.save(saved_name)\n",
    "    print(saved_name, 'saved')\n",
    "else:\n",
    "    print(saved_name, 'exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T10:58:36.195877Z",
     "start_time": "2020-12-09T10:58:36.173110Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val by batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T10:58:37.030856Z",
     "start_time": "2020-12-09T10:58:37.013348Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data = dataGenerator(batch_size,\n",
    "                          val_dir,\n",
    "                          'image',\n",
    "                          'gt',\n",
    "                          dict(),\n",
    "                          image_color_mode='rgb',\n",
    "                          target_size=target_size[:2],\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T11:01:52.151946Z",
     "start_time": "2020-12-09T10:58:37.540895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data in val_data:\n",
    "    print(count)\n",
    "    if count >= val_size:\n",
    "        break\n",
    "    test_imgs, labels = data\n",
    "    res = model.predict(test_imgs)\n",
    "    res = np.asarray(res)\n",
    "    res = res.reshape([res.shape[0]]+list(target_size[:2]))\n",
    "    labels = labels.reshape([res.shape[0]]+list(target_size[:2]))\n",
    "#     print(labels.shape)\n",
    "    length = res.shape[0]\n",
    "    fig = plt.figure(figsize=(5*3,5*length))\n",
    "    for i in range(len(res)):\n",
    "        ax = plt.subplot(length,3,3*i+1)\n",
    "        ax.set_title('Original')\n",
    "        ax.set_axis_off()\n",
    "        plt.imshow(test_imgs[i])\n",
    "        # save image\n",
    "        img = Image.fromarray((test_imgs[i] * 255.).astype(np.uint8))\n",
    "#         img.save(os.path.join('../Predicted/Blur/image/',str(count)+'.png'), 'PNG')    \n",
    "\n",
    "        ax = plt.subplot(length,3,3*i+2)\n",
    "        ax.set_title('Predicted')\n",
    "        ax.set_axis_off()\n",
    "        plt.imshow(res[i], cmap='gray')\n",
    "        # save predicted\n",
    "        predicted_img = Image.fromarray((res[i] * 255.).astype(np.uint8))\n",
    "#         predicted_img.save(os.path.join('../Predicted/Blur/predicted/',str(count)+'.png'), 'PNG')\n",
    "\n",
    "        ax = plt.subplot(length,3,3*i+3)\n",
    "        ax.set_title('Ground Truth')\n",
    "        ax.set_axis_off()\n",
    "        plt.imshow(labels[i], cmap='gray')\n",
    "        # save gt\n",
    "        gt_img = Image.fromarray((labels[i] * 255.).astype(np.uint8))\n",
    "#         gt_img.save(os.path.join('../Predicted/Blur/gt/',str(count)+'.png'), 'PNG')\n",
    "\n",
    "        count += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
